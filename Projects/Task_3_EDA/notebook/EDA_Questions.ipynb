{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894793d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import plotly.express as px \n",
    "import scipy\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"e:/2025/ExtensoData_Internship_Work/Projects/Task_3_EDA/data/cleaned_transactions.csv\")\n",
    "print(df1.info())\n",
    "\n",
    "# changing datetime columun to datetime format\n",
    "df1['transactionDateTime'] = pd.to_datetime(df1['transactionDateTime'])\n",
    "df1[\"accountOpenDate\"] = pd.to_datetime(df1[\"accountOpenDate\"])\n",
    "df1['currentExpDate'] = pd.to_datetime(df1['currentExpDate'])\n",
    "df1['dateOfLastAddressChange'] = pd.to_datetime(df1['dateOfLastAddressChange'])\n",
    "df1['transactionDateTime'].dtype\n",
    "print(df1.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c51053",
   "metadata": {},
   "source": [
    "## Summary Statistics for Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97973e3b",
   "metadata": {},
   "source": [
    "1. What are the min, max, mean, median, and standard deviation of:\n",
    "    - transactionAmount\n",
    "    - availableMoney\n",
    "    - creditLimit\n",
    "    - currentBalance\n",
    "\n",
    "2. Are there outliers or unusually high/low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55013410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 \n",
    "df1[['creditLimit', 'availableMoney', 'transactionAmount', 'currentBalance']].describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f83e0",
   "metadata": {},
   "source": [
    "Insights gained\n",
    "1. Based on Std\n",
    "    - creditLimit : High variation. Some customers have very small limits (250) while others go up to 50000.\n",
    "    - availableMoney : Wide spread, including negative balances. Suggest different usuage patterns- some maxing out cards, others preserving credit.\n",
    "    - transactionAmount: Most people spend small amounts , but a few spend a lot in on ego (1825). So the spending pattern is not the same for everyone.\n",
    "    - currentBalance : Again, wide variablility. Some accounts carry very low(0) while some have very high balances (47496.5)\n",
    "\n",
    "2. Based on other statistics\n",
    "    - Most customers have credit limits below 7500, with 75% under 15000. While few premium accounts with 50,000 credit limits.\n",
    "    - Some accounts appear to be overdrawn (negative values), while 75% have available money below 8000\n",
    "    - 75% of transactions are below 189 and likely to be everyday purchases. Some with high value like 1825 in one go.\n",
    "    - Some have large current balance (47,497) while some have zero balance, average is 4,044."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3a073",
   "metadata": {},
   "source": [
    "## Exploring Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4148c",
   "metadata": {},
   "source": [
    "3. What are the unique values in:\n",
    "    - merchantCategoryCode\n",
    "    - transactionType\n",
    "    - acqCountry\n",
    "    - merchantCountryCode\n",
    "    - merchantName\n",
    "2. What are the most frequet values in those columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5191464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique method for seeing the list of unique values\n",
    "print(\"merchantCategoryCode: \", df1['merchantCategoryCode'].unique())\n",
    "print()\n",
    "print(\"transactionType\", df1['transactionType'].unique())\n",
    "print()\n",
    "print(\"acqCountry\", df1['acqCountry'].unique())\n",
    "print()\n",
    "print(\"merchantName\", df1['merchantName'].unique())\n",
    "print()\n",
    "print(\"merchantCountryCode\", df1['merchantCountryCode'].unique())\n",
    "print()\n",
    "print(\"posEntryMode\",df1['posEntryMode'].unique())\n",
    "print()\n",
    "print(\"posConditionCode\", df1['posConditionCode'].unique()) \n",
    "\n",
    "\n",
    "# nunique method for count value of unique values\n",
    "# Print number of unique values for each\n",
    "print(\"merchantCategoryCode:\", df1['merchantCategoryCode'].nunique())\n",
    "print(\"transactionType:\", df1['transactionType'].nunique())\n",
    "print(\"acqCountry:\", df1['acqCountry'].nunique())\n",
    "print(\"merchantCountryCode:\", df1['merchantCountryCode'].nunique())\n",
    "print(\"merchantName:\", df1['merchantName'].nunique())\n",
    "print('posEntryMode',df1['posEntryMode'].nunique())\n",
    "print('posConditionCode',df1['posConditionCode'].nunique())\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4f139",
   "metadata": {},
   "source": [
    "## Understanding variable (isFraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62b642",
   "metadata": {},
   "source": [
    "5. How many transactions are marked as fraud vs not fraud?\n",
    "6. What is the percentage of fradulent transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by trasnaction time\n",
    "sorted_df = df1.sort_values(by='transactionDateTime', ascending=False)\n",
    "\n",
    "# print(sorted_df.head())\n",
    "\n",
    "#fraud_transactions = sorted_df[sorted_df['isFraud']].value_counts() # this gives dataframe rows\n",
    "fraud_transactions = sorted_df['isFraud'].value_counts()\n",
    "print(fraud_transactions)\n",
    "\n",
    "#percentage of fradulent transactions:\n",
    "percentage_of_fraud = (fraud_transactions[1]/(fraud_transactions[0]+fraud_transactions[1]))*100\n",
    "print(percentage_of_fraud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235f482",
   "metadata": {},
   "source": [
    "## Account and Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6037a",
   "metadata": {},
   "source": [
    "7. How many unique customers are there, and how many accounts per customer?\n",
    "8. Which customers have the highest number of transactions?\n",
    "9. What is total number of transactions?\n",
    "10. Calculate fraudlent transaction frequency for each account\n",
    "11. What is total number of fraudulent transactions?\n",
    "12. Do certain customers/accounts have a higher rate of fradulent transactions?\n",
    "13. What is overall fraud rate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec8b0d",
   "metadata": {},
   "source": [
    "7. How many unique customers are there, and how many accounts per customer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique customer and accounts count\n",
    "# unique_customers= df1['customerId'].unique()\n",
    "# print(f\"Unique customers count: {len(unique_customers)}\")\n",
    "#output: 5000\n",
    "\n",
    "unique_accounts = df1['accountNumber'].unique()\n",
    "print(f\"unique_accounts count: {len(unique_accounts)}\")\n",
    "#output: 5000\n",
    "\n",
    "#(df1['customerId'] == df1['accountNumber']).all()\n",
    "#checked row by row if both are same and found true\n",
    "\n",
    "#df1 = df1.drop('customerId', axis=1)\n",
    "#dropped the customerID column\n",
    "df1.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af537de",
   "metadata": {},
   "source": [
    "8. Which customers have the highest number of transactions?\n",
    "9. What is total number of transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This counts all rows per account, including those with transactionAmount == 0\n",
    "total_transactions_frequency = sorted_df.groupby('accountNumber').size().reset_index(name='transaction_count')\n",
    "print(\"Total Transactions Frequency:\")\n",
    "print(total_transactions_frequency)\n",
    "\n",
    "print(\"Top 10 Highest transaction count and account number\")\n",
    "print(total_transactions_frequency.sort_values(by='transaction_count', ascending=False).head(10))\n",
    "\n",
    "print(f\"\\n🔢 Total number of transactions across all accounts: {total_transactions_frequency['transaction_count'].sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34bc51d",
   "metadata": {},
   "source": [
    "AccountNumber : 318001076 does highest number of transaction in year 2016 i.e. 10,034"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94260f4e",
   "metadata": {},
   "source": [
    "9. Calculate fraudlent transaction frequency for each account\n",
    "10. What is total number of fraudulent transactions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fraud transactions frequency\n",
    "fraud_transactions_frequency = (\n",
    "    sorted_df.groupby(\"accountNumber\")['isFraud']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'isFraud': 'fraud_count'})\n",
    ")\n",
    "print(fraud_transactions_frequency)\n",
    "\n",
    "# Now sort the DataFrame by the newly named column\n",
    "print(\"Top 10 Highest fraudulent transaction count and account number\")\n",
    "print(fraud_transactions_frequency.sort_values(by='fraud_count', ascending=False).head(10))\n",
    "\n",
    "print(f\"🚨 Total number of fraudulent transactions across all accounts: {fraud_transactions_frequency['fraud_count'].sum()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65679c9",
   "metadata": {},
   "source": [
    "11. What is fraud rate per account?\n",
    "12. Do certain customers/accounts have a higher rate of fradulent transactions?\n",
    "13. What is overall fraud rate ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on 'accountNumber'\n",
    "merged_data = pd.merge(total_transactions_frequency, fraud_transactions_frequency, on='accountNumber', how='left')\n",
    "\n",
    "# Calculate the percentage of fraudulent transactions per account\n",
    "merged_data['fraud_percentage'] = (merged_data['fraud_count'] / merged_data['transaction_count']) * 100\n",
    "\n",
    "# Handling missing fraud counts: Replace NaN with 0 (if an account has no fraud)\n",
    "merged_data['fraud_percentage'] = merged_data['fraud_percentage'].fillna(0)\n",
    "\n",
    "# Print the percentage of fraudulent transactions for the top 10 accounts, along with accountNumber\n",
    "print(\"Top 10 Accounts with highest fraud percentage and their fraud percentage\")\n",
    "print(merged_data[['accountNumber', 'fraud_percentage']].sort_values(by='fraud_percentage', ascending=False).head(10))\n",
    "\n",
    "# ✅ Total number of transactions in the entire dataset\n",
    "total_transactions = total_transactions_frequency['transaction_count'].sum()\n",
    "\n",
    "# ✅ Total number of fraudulent transactions\n",
    "fraud_transactions_frequency['fraud_count'] = fraud_transactions_frequency['fraud_count'].fillna(0)\n",
    "total_fraud_transactions = fraud_transactions_frequency['fraud_count'].sum()\n",
    "print(f\"🚨 Total number of fraudulent transactions across all accounts: {int(total_fraud_transactions)}\")\n",
    "\n",
    "overall_fraud_rate = (total_fraud_transactions / total_transactions) * 100\n",
    "print(f\"⚠️ Overall fraud rate in the dataset: {overall_fraud_rate:.2f}%\")\n",
    "\n",
    "print(merged_data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342283e1",
   "metadata": {},
   "source": [
    "Insights\n",
    "1. Highest number of transaction is 10,034 by account number 318001076.\n",
    "2. Highest number of fraudulent transaction is 302 by account number 311710839.\n",
    "3. Fraud_percentage is 100% for account 981286839 , and 50% for account 638423733.\n",
    "4. Total number of transactions acroll all accounts: 641914\n",
    "5. Total number of fraudulent transactions across all accounts: 11302\n",
    "6. Overall fraud rate is 1.76%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8bc37",
   "metadata": {},
   "source": [
    "## Customer, CVV, expirationDate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9038ca",
   "metadata": {},
   "source": [
    "14. Normally after how long time of opening account the address is changed?\n",
    "15. From today's date it we see which are the oldest and newest accounts\n",
    "16. In which day maximum accounts are opened?\n",
    "17. Check enteredCVV and cardCVV mismatches, and calculate percentage of mismatch\n",
    "18. Compare cvv_mismatch and isFraud using crosstab (or contingency table) \n",
    "19. Compare expirationDateKeyInMatch with isFraud using crosstab\n",
    "20. Whose customers card expiration date is near?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727254ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns related to customer information\n",
    "customer_columns = [\n",
    "    'accountNumber',\n",
    "    'customerId',\n",
    "    'creditLimit',\n",
    "    'availableMoney',\n",
    "    'cardCVV',\n",
    "    'enteredCVV',\n",
    "    'cardLast4Digits',\n",
    "    'currentExpDate',\n",
    "    'accountOpenDate',\n",
    "    'dateOfLastAddressChange',\n",
    "    'currentBalance',\n",
    "    'expirationDateKeyInMatch',\n",
    "    'cardPresent'\n",
    "]\n",
    "\n",
    "# # Create the customer DataFrame\n",
    "customer_df = df1[customer_columns].drop_duplicates(subset='accountNumber').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Preview the DataFrame\n",
    "print(\"Customer DataFrame:\")\n",
    "print(customer_df.head())\n",
    "\n",
    "print(df1.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b26f3a",
   "metadata": {},
   "source": [
    "14. Normally after how long time of opening account the address is changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['add_change_gap'] = (customer_df['dateOfLastAddressChange']- customer_df['accountOpenDate']).dt.days\n",
    "print(customer_df[['accountNumber','add_change_gap']].sort_values(by='add_change_gap', ascending=False).reset_index(drop=True).head(10))\n",
    "\n",
    "average_gap = customer_df['add_change_gap'].mean()\n",
    "print(f\"\\nOverall average address change gap (in days): {average_gap: .2f}\")\n",
    "\n",
    "print(\"After opening account how many customer have changed the address\")\n",
    "changed_after_opening = customer_df[customer_df['add_change_gap']>0]\n",
    "\n",
    "print(f\"\\nNumber of customers who changed the address after opening account: {changed_after_opening.shape[0]} \")\n",
    "print(changed_after_opening[['accountNumber','add_change_gap']].sort_values(by='add_change_gap',ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f116d8",
   "metadata": {},
   "source": [
    "15. From today's date it we see which are the oldest and newest accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_df = customer_df.drop(columns=['accountAge'])\n",
    "today = pd.Timestamp.today()\n",
    "customer_df['accountAge'] = (today - customer_df['accountOpenDate']).dt.days\n",
    "\n",
    "print(\"\\nTop 5 oldest accounts:\")\n",
    "print(customer_df[['accountNumber','accountOpenDate','accountAge']]\n",
    "      .sort_values(by='accountAge', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    "      .head())\n",
    "\n",
    "print(\"\\nTop 5 new accounts\")\n",
    "print(customer_df[['accountNumber','accountOpenDate','accountAge']]\n",
    "      .sort_values(by='accountAge',ascending=True)\n",
    "      .reset_index(drop=True)\n",
    "      .head())\n",
    "\n",
    "#Oldest account\n",
    "oldest_account = customer_df.loc[customer_df['accountAge'].idxmax()]\n",
    "print(f\"\\n The oldest account is:\\nAccount Number: {oldest_account['accountNumber']},\"\n",
    "      f\"Opened on: {oldest_account['accountOpenDate'].date()} ,\"\n",
    "      f\" Age: {oldest_account['accountAge']} days \")\n",
    "\n",
    "#finding the newest account\n",
    "\n",
    "newest_account = customer_df.loc[customer_df['accountAge'].idxmin()]\n",
    "\n",
    "print(f\"\\n The newest account is:\\nAccount Number: {newest_account['accountNumber']},\"\n",
    "      f\"Opened on: {newest_account['accountOpenDate'].date()} ,\"\n",
    "      f\" Age: {newest_account['accountAge']} days \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f953d",
   "metadata": {},
   "source": [
    "16. In which day maximum accounts are opened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f737dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_open_day_counts = customer_df.groupby('accountOpenDate').size()\n",
    "\n",
    "max_open_day = account_open_day_counts.idxmax()\n",
    "max_open_count = account_open_day_counts.max()\n",
    "\n",
    "print(\"\\n Top 5 days with most account openings:\")\n",
    "print(account_open_day_counts.sort_values(ascending=False).head(50))\n",
    "\n",
    "print(f\"The maximum number of accounts were opened on {max_open_day.date()},with {max_open_count} accounts.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ec58f",
   "metadata": {},
   "source": [
    "17. Check mismatches between entered CVV and actual CVV and calculate mismatch_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ade8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new column to mark mismatches between entered and actual CVV\n",
    "sorted_df['cvv_mismatch'] = sorted_df['enteredCVV'] != sorted_df['cardCVV']\n",
    "\n",
    "print(sorted_df.groupby('accountNumber')['cvv_mismatch'].sum().sort_values(ascending=False))\n",
    "\n",
    "# Step 2: Group by account and calculate total transactions and mismatches\n",
    "fraudulent_df = sorted_df.groupby('accountNumber').agg(\n",
    "    total_transactions=('cvv_mismatch', 'count'),\n",
    "    mismatch_count=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Calculate percentage of mismatches\n",
    "fraudulent_df['mismatch_percentage'] = (fraudulent_df['mismatch_count'] / fraudulent_df['total_transactions']) * 100\n",
    "\n",
    "\n",
    "\n",
    "#fradulent_df only contains those accounts whose cvv mismatch_percentage is greater than 0\n",
    "\n",
    "fraudulent_df = fraudulent_df[fraudulent_df['mismatch_percentage']>0]\n",
    "\n",
    "print(fraudulent_df.sort_values(by='mismatch_percentage',ascending=False).head(10))\n",
    "\n",
    "# Filter accounts with more than 10% mismatch, then sort by mismatch percentage\n",
    "print(fraudulent_df[fraudulent_df['mismatch_percentage'] > 10].sort_values(by='mismatch_percentage', ascending=False).head(40).reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896384cc",
   "metadata": {},
   "source": [
    "We checked for enteredCVV and  cardCVV mismatch, first we counted the total transactions number and then mismatch count for each account number and then grouped those accounts whose mismatch_percentage is greater than 0 in a dataframe fradulent_df.\n",
    "\n",
    "In fradulent_df one account with 95.65% mismatch rate, similary 39 accounts with mismatch rate above 10%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dc831",
   "metadata": {},
   "source": [
    "18. Now check cardpresent = False case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628489d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check distinct values in 'cardPresent' column\n",
    "print(sorted_df['cardPresent'].unique())\n",
    "print(sorted_df['cardPresent'].value_counts(dropna=False))\n",
    "\n",
    "# Step 2: Filter data for card-absent transactions\n",
    "card_absent_df = sorted_df[sorted_df['cardPresent'] == False]\n",
    "\n",
    "# Step 3: Group and compute mismatch stats for card-absent transactions\n",
    "fraudulent_card_absent_df = card_absent_df.groupby('accountNumber').agg(\n",
    "    total_transactions_card_absent=('cvv_mismatch', 'count'),\n",
    "    cvv_mismatch_count_card_absent=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 4: Calculate mismatch percentage\n",
    "fraudulent_card_absent_df['cvv_mismatch_percentage_card_absent'] = (\n",
    "    fraudulent_card_absent_df['cvv_mismatch_count_card_absent'] / fraudulent_card_absent_df['total_transactions_card_absent']\n",
    ") * 100\n",
    "\n",
    "\n",
    "total_mismatches_while_card_absent = card_absent_df['cvv_mismatch'].sum()\n",
    "print(\"Total CVV mismatches (card absent):\", total_mismatches_while_card_absent)\n",
    "\n",
    "# Step 6: Calculate totals\n",
    "total_transactions = fraudulent_card_absent_df['total_transactions_card_absent'].sum()\n",
    "total_mismatches = fraudulent_card_absent_df['cvv_mismatch_count_card_absent'].sum()\n",
    "\n",
    "# Step 7: Calculate overall percentage\n",
    "overall_mismatch_percentage = (total_mismatches / total_transactions) * 100\n",
    "\n",
    "# Step 8: Create a summary row as a DataFrame\n",
    "summary_row = pd.DataFrame({\n",
    "    'accountNumber': ['TOTAL'],\n",
    "    'total_transactions_card_absent': [total_transactions],\n",
    "    'cvv_mismatch_count_card_absent': [total_mismatches],\n",
    "    'cvv_mismatch_percentage_card_absent': [overall_mismatch_percentage]\n",
    "})\n",
    "\n",
    "# Step 9: Append the summary row to the original DataFrame\n",
    "fraudulent_card_absent_df = pd.concat([fraudulent_card_absent_df, summary_row], ignore_index=True)\n",
    "\n",
    "# # Step 10: Print the final DataFrame\n",
    "# print(fraudulent_df1)\n",
    "\n",
    "# print(\"Top 20 accounts with card absent and high cvv mismatch rate\")\n",
    "# print(fraudulent_df1.sort_values(by='cvv_mismatch_percentage_card_absent', ascending=False).head(20).reset_index(drop=True))\n",
    "\n",
    "print(\"Creating fraudulent_df2 to store data for cvv_mismatch_percentage_card_absent greater than 10%\")\n",
    "\n",
    "fraudulent_card_absent_df1 = fraudulent_card_absent_df[fraudulent_card_absent_df['cvv_mismatch_percentage_card_absent']>10]\n",
    "print(fraudulent_card_absent_df1.sort_values(by='cvv_mismatch_percentage_card_absent',ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab73f3e",
   "metadata": {},
   "source": [
    "Total transaction with card not present( card absent) are: 340453\n",
    "Total trasnaction with card absent and cvvMismatch are: 3120\n",
    "For this case cvv_mismatch_percentage_card_present > 10 are kept in dataframe: fraudulent_card_absent_df1\n",
    "There are accounts with 100% mismatch percentage (238223440 - 9/9), (443926651 - 1/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba97ce",
   "metadata": {},
   "source": [
    "19. cardPresent = True case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5498bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter data for card-present transactions\n",
    "card_present_df = sorted_df[sorted_df['cardPresent'] == True]\n",
    "\n",
    "# Step 2: Group and compute CVV mismatch stats for card-present transactions\n",
    "fraudulent_card_present_df = card_present_df.groupby('accountNumber').agg(\n",
    "    total_transactions_card_present=('cvv_mismatch', 'count'),\n",
    "    cvv_mismatch_count_card_present=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Calculate mismatch percentage\n",
    "fraudulent_card_present_df['cvv_mismatch_percentage_card_present'] = (\n",
    "    fraudulent_card_present_df['cvv_mismatch_count_card_present'] / fraudulent_card_present_df['total_transactions_card_present']\n",
    ") * 100\n",
    "\n",
    "# Step 4: Add summary row (totals)\n",
    "summary_row_present = pd.DataFrame({\n",
    "    'accountNumber': ['TOTAL'],\n",
    "    'total_transactions_card_present': [fraudulent_card_present_df['total_transactions_card_present'].sum()],\n",
    "    'cvv_mismatch_count_card_present': [fraudulent_card_present_df['cvv_mismatch_count_card_present'].sum()],\n",
    "    'cvv_mismatch_percentage_card_present': [\n",
    "        (fraudulent_card_present_df['cvv_mismatch_count_card_present'].sum() / \n",
    "         fraudulent_card_present_df['total_transactions_card_present'].sum()) * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "fraudulent_card_present_df = pd.concat([fraudulent_card_present_df, summary_row_present], ignore_index=True)\n",
    "print(fraudulent_card_present_df)\n",
    "\n",
    "# Step 5: Filter accounts with >10% mismatch\n",
    "fraudulent_card_present_df1 = fraudulent_card_present_df[\n",
    "    fraudulent_card_present_df['cvv_mismatch_percentage_card_present'] > 10\n",
    "]\n",
    "\n",
    "# Display results\n",
    "print(fraudulent_card_present_df1.sort_values(by='cvv_mismatch_percentage_card_present', ascending=False).reset_index(drop=True).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd5379",
   "metadata": {},
   "source": [
    "Total transaction with card present are: 301461\n",
    "Total trasnaction with card present and cvvMismatch are: 2817\n",
    "For this case cvv_mismatch_percentage_card_present > 10 are kept in dataframe: fraudulent_card_present_df1\n",
    "There are accounts with 100% mismatch percentage (140105230 - 11/11), (380948187 - 1/1), (386190390 - 1/1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0816a",
   "metadata": {},
   "source": [
    "20. CVV Mismatch and isFraud Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1582a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.shape\n",
    "sorted_df.columns\n",
    "fraud_crosstab = pd.crosstab(\n",
    "    sorted_df['cvv_mismatch'],\n",
    "    sorted_df['isFraud'],\n",
    "    rownames=['CVV Mismatch'],\n",
    "    colnames=['Is Fraud'],\n",
    "    margins=True  # adds totals for rows and columns\n",
    ")\n",
    "\n",
    "print(fraud_crosstab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396175b8",
   "metadata": {},
   "source": [
    "Most transactions (635,977 out of 641,914) did not have a CVV mismatch.\n",
    "\n",
    "CVV mismatch occurred in only ~0.92% of transactions (5937 / 641914).\n",
    "\n",
    "Fraud rate when CVV matched:\n",
    "\n",
    "11,107 / 635,977 ≈ 1.75%\n",
    "\n",
    "Fraud rate when CVV mismatched:\n",
    "\n",
    "195 / 5,937 ≈ 3.28%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae18420",
   "metadata": {},
   "source": [
    "21. expirationDateKeyInMatch and isFraud comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b272b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sorted_df['expirationDateKeyInMatch'].unique())\n",
    "\n",
    "sorted_df[\"expirationDateKeyInMatch\"].value_counts()\n",
    "expiration_fraud_crosstab_percent = pd.crosstab(\n",
    "    sorted_df['expirationDateKeyInMatch'],\n",
    "    sorted_df['isFraud'],\n",
    "    rownames=['expiration_Mismtach'],\n",
    "    colnames=['Is Fraud'],\n",
    "    margins=True  # adds totals for rows and columns\n",
    ")\n",
    "\n",
    "print(expiration_fraud_crosstab_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafec763",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. Only 969 transactions had an expiration date mismatch — a very small fraction (~0.15%) of total transactions.\n",
    "2. Fraud rate when expiration matched: 11289/640945 =  approx. 1.76%\n",
    "3. Fraud rate when expiration mismatched: 13/969 = approx. 1.34%\n",
    "\n",
    "\n",
    "❗ Insight:\n",
    "Surprisingly, the fraud rate is slightly lower when expiration mismatches occur (1.34%) than when they match (1.76%).\n",
    "\n",
    "This suggests that expiration date mismatches are not a strong indicator of fraud in dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6962b2",
   "metadata": {},
   "source": [
    "## posEntryMode and posConditionCode Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ea282",
   "metadata": {},
   "source": [
    "11. What are the most frequent POS entry modes?\n",
    "12. Is fraud more common in any particular entry mode?\n",
    "13. Are online (keyed) vs card-present( swiped/tapped) entry modes associated with different transaction amounts?\n",
    "14. What are the most common POS condition codes?\n",
    "15. How different condition codes relate to fraud?\n",
    "16. Are some condition codes tried to specific merchant categories or regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5669b",
   "metadata": {},
   "source": [
    "11. What are the most frequent POS entry modes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5600d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['posEntryMode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578d71f",
   "metadata": {},
   "source": [
    "Most frequent POS Entry Modes are 5 (chip read), 9(Manual entry), and 2 (Magnetic Strip swipe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543ee3d",
   "metadata": {},
   "source": [
    "12. Is fraud more common in any particular entry mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_entry = (sorted_df.groupby('posEntryMode')['isFraud'].mean()*100).sort_values(ascending = False)\n",
    "print(fraud_by_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed34db",
   "metadata": {},
   "source": [
    "Yes, Fraud rate is more common in Manual Entry(9) 2.7% and Advanced methods (QR, bluetooth , wallets ->90) 2.01 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ace3561",
   "metadata": {},
   "source": [
    "13. Are online (keyed) vs card-present( swiped/tapped) entry modes associated with different transaction amounts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1485c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 count        mean         std  min    25%    50%     75%  \\\n",
      "entry_mode                                                                  \n",
      "Card Present  301461.0  141.927444  146.519247  0.0  40.45  92.42  195.77   \n",
      "Online/Keyed  340453.0  129.172338  147.265608  0.0  23.15  79.76  182.53   \n",
      "\n",
      "                  max  \n",
      "entry_mode             \n",
      "Card Present  1743.51  \n",
      "Online/Keyed  1825.25  \n"
     ]
    }
   ],
   "source": [
    "sorted_df['entry_mode'] = sorted_df['cardPresent'].map({True: 'Card Present', False: 'Online/Keyed'})\n",
    "entry_mode_stats = sorted_df.groupby('entry_mode')['transactionAmount'].describe()\n",
    "print(entry_mode_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca768f4",
   "metadata": {},
   "source": [
    "14. What are the most common POS condition codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['posConditionCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5867d",
   "metadata": {},
   "source": [
    "Customer present (Chip read or magnetic swipe can be used) is most common POS condition followed by Mail/Phone/Online Order (card-not-present).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bd5ea",
   "metadata": {},
   "source": [
    "15. How different condition codes relate to fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_condition = (sorted_df.groupby('posConditionCode')['isFraud'].mean()*100).sort_values(ascending = False)\n",
    "print(fraud_by_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d49b7",
   "metadata": {},
   "source": [
    "99.0\tUnknown or other — This might be used when the system can’t determine the condition of the transaction. This could also represent some fraudulent or suspicious activity or any conditions that don’t fit into the usual categories.\n",
    "\n",
    "Approx 3.68 percentage of fraudulent in posConditionCode 99, followed by approx. 1.82 in posConditionCode 1 and at last for 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d866f",
   "metadata": {},
   "source": [
    "16. Are some condition codes tried to specific merchant categories or regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sorted_df['posConditionCode'], sorted_df['merchantCategoryCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab96a1",
   "metadata": {},
   "source": [
    "This shows all transaction are happening mostly through posConditionCode 1 (customer present) in all merchant category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad4105",
   "metadata": {},
   "source": [
    "By Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96056bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sorted_df['posConditionCode'], sorted_df['acqCountry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79c8eb",
   "metadata": {},
   "source": [
    "## Date and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da82fee",
   "metadata": {},
   "source": [
    "17. Are there time periods with more fraud?\n",
    "18. Is fraud more common during weekends or weekday?\n",
    "19. What is the age of accounts? (opendate to first transaction date)/ (current date - open date)\n",
    "20. Do newer accounts have more fraud compared to older ones?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3ceee",
   "metadata": {},
   "source": [
    "17. Are there time periods with more fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e270399",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_hour = sorted_df.groupby('txn_hour')['isFraud'].mean()\n",
    "fraud_by_day = sorted_df.groupby('txn_day')['isFraud'].mean()\n",
    "fraud_by_month = sorted_df.groupby('txn_month')['isFraud'].mean()\n",
    "\n",
    "print((fraud_by_hour*100).sort_values(ascending=False))\n",
    "print((fraud_by_day*100).sort_values(ascending=False))\n",
    "print((fraud_by_month*100).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e618f68",
   "metadata": {},
   "source": [
    "18. Is fraud more common during weekends or weekday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8330be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['weekday'] = sorted_df['transactionDateTime'].dt.weekday\n",
    "sorted_df['is_weekend'] = sorted_df['weekday'].isin([5, 6])\n",
    "\n",
    "sorted_df.groupby('is_weekend')['isFraud'].mean()\n",
    "\n",
    "sorted_df['weekday_name'] = sorted_df['transactionDateTime'].dt.day_name()\n",
    "\n",
    "# Count of all transactions by weekday\n",
    "total_txns = sorted_df['weekday_name'].value_counts().sort_index()\n",
    "\n",
    "# Count of fraudulent transactions by weekday\n",
    "fraud_txns = sorted_df[sorted_df['isFraud'] == True]['weekday_name'].value_counts().sort_index()\n",
    "\n",
    "# Combine into a summary table\n",
    "weekday_summary = pd.DataFrame({\n",
    "    'Total_Transactions': total_txns,\n",
    "    'Fraud_Transactions': fraud_txns\n",
    "}).fillna(0)\n",
    "\n",
    "# Add fraud rate\n",
    "weekday_summary['Fraud_Rate'] = (weekday_summary['Fraud_Transactions'] / weekday_summary['Total_Transactions'])*100\n",
    "weekday_summary = weekday_summary.sort_values('Fraud_Rate', ascending=False)\n",
    "weekday_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced3f18",
   "metadata": {},
   "source": [
    "High Fraud in weekends (1.79% is Sunday and 1.78% in Saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f2be8",
   "metadata": {},
   "source": [
    "19. What is the age of accounts? (opendate to first transaction date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['account_age_days'] = (sorted_df['transactionDateTime'] - sorted_df['accountOpenDate']).dt.days\n",
    "\n",
    "# Sort by account age in descending order\n",
    "print(sorted_df[['accountNumber', 'account_age_days']].sort_values(by='account_age_days', ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450009e",
   "metadata": {},
   "source": [
    "20. Do newer accounts have more fraud compared to older ones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['age_bin'] = pd.cut(sorted_df['account_age_days'], bins=[0,30,90,180,365,10000])\n",
    "\n",
    "# Group by age bins and compute fraud rate\n",
    "fraud_rate_by_age = sorted_df.groupby('age_bin', observed=True)['isFraud'].mean()*100\n",
    "\n",
    "print(fraud_rate_by_age)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
