{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894793d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import plotly.express as px \n",
    "import scipy\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"e:/2025/ExtensoData_Internship_Work/Projects/Task_3_EDA/data/cleaned_transactions.csv\")\n",
    "print(df1.info())\n",
    "\n",
    "# changing datetime columun to datetime format\n",
    "df1['transactionDateTime'] = pd.to_datetime(df1['transactionDateTime'])\n",
    "df1[\"accountOpenDate\"] = pd.to_datetime(df1[\"accountOpenDate\"])\n",
    "df1['currentExpDate'] = pd.to_datetime(df1['currentExpDate'])\n",
    "df1['dateOfLastAddressChange'] = pd.to_datetime(df1['dateOfLastAddressChange'])\n",
    "df1['transactionDateTime'].dtype\n",
    "print(df1.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c51053",
   "metadata": {},
   "source": [
    "## Summary Statistics for Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97973e3b",
   "metadata": {},
   "source": [
    "1. What are the min, max, mean, median, and standard deviation of:\n",
    "    - transactionAmount\n",
    "    - availableMoney\n",
    "    - creditLimit\n",
    "    - currentBalance\n",
    "\n",
    "2. Are there outliers or unusually high/low values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55013410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1 \n",
    "df1[['creditLimit', 'availableMoney', 'transactionAmount', 'currentBalance']].describe()\n",
    "\n",
    "# df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ed352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[['creditLimit','availableMoney','transactionAmount','currentBalance']].hist(figsize=(15, 10), bins=30, edgecolor='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f83e0",
   "metadata": {},
   "source": [
    "Insights gained\n",
    "1. Based on Std\n",
    "    - creditLimit : High variation. Some customers have very small limits (250) while others go up to 50000.\n",
    "    - availableMoney : Wide spread, including negative balances. Suggest different usuage patterns- some maxing out cards, others preserving credit.\n",
    "    - transactionAmount: Most people spend small amounts , but a few spend a lot in on ego (1825). So the spending pattern is not the same for everyone.\n",
    "    - currentBalance : Again, wide variablility. Some accounts carry very low(0) while some have very high balances (47496.5)\n",
    "\n",
    "2. Based on other statistics\n",
    "    - Most customers have credit limits below 7500, with 75% under 15000. While few premium accounts with 50,000 credit limits.\n",
    "    - Some accounts appear to be overdrawn (negative values), while 75% have available money below 8000\n",
    "    - 75% of transactions are below 189 and likely to be everyday purchases. Some with high value like 1825 in one go.\n",
    "    - Some have large current balance (47,497) while some have zero balance, average is 4,044."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7558fca",
   "metadata": {},
   "source": [
    "2. Are there outliers or unusually high/low values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualzing outliers\n",
    "\n",
    "# Boxplot for all four columns\n",
    "cols = ['creditLimit', 'availableMoney', 'transactionAmount', 'currentBalance']\n",
    "for col in cols:\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    sns.boxplot(x=df1[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3a073",
   "metadata": {},
   "source": [
    "## Exploring Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4148c",
   "metadata": {},
   "source": [
    "3. What are the unique values in:\n",
    "    - merchantCategoryCode\n",
    "    - transactionType\n",
    "    - acqCountry\n",
    "    - merchantCountryCode\n",
    "    - merchantName\n",
    "4. What are the most frequet values in those columns?\n",
    "5. What are the most common merchants and merchant categories by transaction count and amount?\n",
    "6. How does transaction frequency and amount vary by country, state, or city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5191464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique method for seeing the list of unique values\n",
    "print(\"merchantCategoryCode: \", df1['merchantCategoryCode'].unique())\n",
    "print()\n",
    "print(\"transactionType\", df1['transactionType'].unique())\n",
    "print()\n",
    "print(\"acqCountry\", df1['acqCountry'].unique())\n",
    "print()\n",
    "print(\"merchantName\", df1['merchantName'].unique())\n",
    "print()\n",
    "print(\"merchantCountryCode\", df1['merchantCountryCode'].unique())\n",
    "print()\n",
    "print(\"posEntryMode\",df1['posEntryMode'].unique())\n",
    "print()\n",
    "print(\"posConditionCode\", df1['posConditionCode'].unique()) \n",
    "\n",
    "\n",
    "# nunique method for count value of unique values\n",
    "# Print number of unique values for each\n",
    "print(\"merchantCategoryCode:\", df1['merchantCategoryCode'].nunique())\n",
    "print(\"transactionType:\", df1['transactionType'].nunique())\n",
    "print(\"acqCountry:\", df1['acqCountry'].nunique())\n",
    "print(\"merchantCountryCode:\", df1['merchantCountryCode'].nunique())\n",
    "print(\"merchantName:\", df1['merchantName'].nunique())\n",
    "print('posEntryMode',df1['posEntryMode'].nunique())\n",
    "print('posConditionCode',df1['posConditionCode'].nunique())\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d774154",
   "metadata": {},
   "source": [
    "Most Frequent (Mode) Values in These Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most frequent merchantCategoryCode:\\n\", df1['merchantCategoryCode'].value_counts().head())\n",
    "print(\"Most frequent transactionType:\\n\", df1['transactionType'].value_counts().head())\n",
    "print(\"Most frequent acqCountry:\\n\", df1['acqCountry'].value_counts().head())\n",
    "print(\"Most frequent merchantCountryCode:\\n\", df1['merchantCountryCode'].value_counts().head())\n",
    "print(\"Most frequent merchantName:\\n\", df1['merchantName'].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8904892",
   "metadata": {},
   "source": [
    "Most Common Merchants & Merchant Categories by Transaction Count and Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f75c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By transaction count\n",
    "top_merchants_by_count = df1.groupby('merchantName').size().sort_values(ascending=False).head()\n",
    "top_categories_by_count = df1.groupby('merchantCategoryCode').size().sort_values(ascending=False).head()\n",
    "\n",
    "# By transaction amount\n",
    "top_merchants_by_amount = df1.groupby('merchantName')['transactionAmount'].sum().sort_values(ascending=False).head()\n",
    "top_categories_by_amount = df1.groupby('merchantCategoryCode')['transactionAmount'].sum().sort_values(ascending=False).head()\n",
    "\n",
    "print(\"Top merchants by transaction count:\\n\", top_merchants_by_count)\n",
    "print()\n",
    "print(\"Top categories by transaction count:\\n\", top_categories_by_count)\n",
    "print()\n",
    "print(\"Top merchants by transaction amount:\\n\", top_merchants_by_amount)\n",
    "print()\n",
    "print(\"Top categories by transaction amount:\\n\", top_categories_by_amount)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190960db",
   "metadata": {},
   "source": [
    "Transaction Frequency and Amount by Country, State, or City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc345ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency and amount by country\n",
    "country_summary = df1.groupby('acqCountry').agg({\n",
    "    'transactionAmount': ['count', 'sum', 'mean']\n",
    "}).sort_values(('transactionAmount', 'count'), ascending=False)\n",
    "\n",
    "\n",
    "print(\"Transaction summary by country:\\n\", country_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4f139",
   "metadata": {},
   "source": [
    "## Understanding variable (isFraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62b642",
   "metadata": {},
   "source": [
    "7. How many transactions are marked as fraud vs not fraud?\n",
    "8. What is the percentage of fradulent transactions?\n",
    "9. In which merchantName and merchant Category fraudulent transactions occur most?\n",
    "10. In which country fraudulent transactions occur most?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by trasnaction time\n",
    "sorted_df = df1.sort_values(by='transactionDateTime', ascending=False)\n",
    "\n",
    "print(sorted_df.shape)\n",
    "\n",
    "# print(sorted_df.head())\n",
    "\n",
    "#fraud_transactions = sorted_df[sorted_df['isFraud']].value_counts() # this gives dataframe rows\n",
    "fraud_transactions = sorted_df['isFraud'].value_counts()\n",
    "print(fraud_transactions)\n",
    "\n",
    "#percentage of fradulent transactions:\n",
    "percentage_of_fraud = (fraud_transactions[1]/(fraud_transactions[0]+fraud_transactions[1]))*100\n",
    "print(percentage_of_fraud)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = df1[df1['isFraud']==True]\n",
    "\n",
    "#Most common merchant names in frauds\n",
    "top_merchants_by_fraud = fraud_df['merchantName'].value_counts().head()\n",
    "\n",
    "top_merchantsCategories_by_fraud = fraud_df['merchantCategoryCode'].value_counts().head()\n",
    "\n",
    "print(\"Top merchants in fraudulent transactions:\\n\", top_merchants_by_fraud)\n",
    "print(\"Top merchant categories in fraudulent transactions: \\n\", top_merchantsCategories_by_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Top 5 fraudulent merchants\n",
    "sns.barplot(x=top_merchants_by_fraud.values, y=top_merchants_by_fraud.index, hue=top_merchants_by_fraud.index,palette='Reds_r')\n",
    "plt.title(\"Top 5 Fraudulent Merchant Names\")\n",
    "plt.xlabel(\"Number of Fraudulent Transactions\")\n",
    "plt.ylabel(\"Merchant Name\")\n",
    "plt.show()\n",
    "\n",
    "# Top 5 fraudulent merchant categories\n",
    "sns.barplot(x=top_merchantsCategories_by_fraud.values, y=top_merchantsCategories_by_fraud.index, hue=top_merchantsCategories_by_fraud, palette='Reds_r')\n",
    "plt.title(\"Top 5 Fraudulent Merchant Categories\")\n",
    "plt.xlabel(\"Number of Fraudulent Transactions\")\n",
    "plt.ylabel(\"Merchant Category\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971defb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent countries for fraud\n",
    "fraud_by_country = fraud_df['acqCountry'].value_counts().head()\n",
    "\n",
    "print(\"Countries with most fraudulent transactions:\\n\", fraud_by_country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235f482",
   "metadata": {},
   "source": [
    "## Account and Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c6037a",
   "metadata": {},
   "source": [
    "11. How many unique customers are there, and how many accounts per customer?\n",
    "8. Which customers have the highest number of transactions?\n",
    "9. What is total number of transactions?\n",
    "10. Calculate fraudlent transaction frequency for each account\n",
    "11. What is total number of fraudulent transactions?\n",
    "12. Do certain customers/accounts have a higher rate of fradulent transactions?\n",
    "13. What is overall fraud rate ?\n",
    "14. Is there a difference in spending behavior between fraudulent and non-fraudulent transactions?\n",
    "15. What is the highest transaction amount?\n",
    "    What is the distribution of transactionAmount? Are there any outliers?\n",
    "    What is the overall transaction amount and top accounts by that?\n",
    "16. Available Amount vs isFraud\n",
    "17. currentBalance vs isFraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ec8b0d",
   "metadata": {},
   "source": [
    "11. How many unique customers are there, and how many accounts per customer?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique customer and accounts count\n",
    "# unique_customers= df1['customerId'].unique()\n",
    "# print(f\"Unique customers count: {len(unique_customers)}\")\n",
    "#output: 5000\n",
    "\n",
    "unique_accounts = df1['accountNumber'].unique()\n",
    "print(f\"unique_accounts count: {len(unique_accounts)}\")\n",
    "#output: 5000\n",
    "\n",
    "#(df1['customerId'] == df1['accountNumber']).all()\n",
    "#checked row by row if both are same and found true\n",
    "\n",
    "#df1 = df1.drop('customerId', axis=1)\n",
    "#dropped the customerID column\n",
    "df1.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af537de",
   "metadata": {},
   "source": [
    "12. Which customers have the highest number of transactions?\n",
    "9. What is total number of transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This counts all rows per account, including those with transactionAmount == 0\n",
    "total_transactions_frequency = sorted_df.groupby('accountNumber').size().reset_index(name='transaction_count')\n",
    "print(\"Total Transactions Frequency:\")\n",
    "print(total_transactions_frequency)\n",
    "\n",
    "print(\"Top 10 Highest transaction count and account number\")\n",
    "print(total_transactions_frequency.sort_values(by='transaction_count', ascending=False).head(10).reset_index(drop=True))\n",
    "\n",
    "print(f\"\\n🔢 Total number of transactions across all accounts: {total_transactions_frequency['transaction_count'].sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34bc51d",
   "metadata": {},
   "source": [
    "AccountNumber : 318001076 does highest number of transaction in year 2016 i.e. 10,034"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94260f4e",
   "metadata": {},
   "source": [
    "14. Calculate fraudlent transaction frequency for each account\n",
    "10. What is total number of fraudulent transactions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fraud transactions frequency\n",
    "fraud_transactions_frequency = (\n",
    "    sorted_df.groupby(\"accountNumber\")['isFraud']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={'isFraud': 'fraud_count'})\n",
    ")\n",
    "print(fraud_transactions_frequency)\n",
    "\n",
    "# Now sort the DataFrame by the newly named column\n",
    "print(\"Top 10 Highest fraudulent transaction count and account number\")\n",
    "print(fraud_transactions_frequency.sort_values(by='fraud_count', ascending=False).head(10).reset_index(drop=True))\n",
    "\n",
    "print(f\"🚨 Total number of fraudulent transactions across all accounts: {fraud_transactions_frequency['fraud_count'].sum()}\")\n",
    "\n",
    "sorted_df.info()\n",
    "fraud_transactions_frequency.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b246c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c65679c9",
   "metadata": {},
   "source": [
    "16. What is fraud rate per account?\n",
    "12. Do certain customers/accounts have a higher rate of fradulent transactions?\n",
    "13. What is overall fraud rate ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on 'accountNumber'\n",
    "merged_data = pd.merge(total_transactions_frequency, fraud_transactions_frequency, on='accountNumber', how='left')\n",
    "\n",
    "# Calculate the percentage of fraudulent transactions per account\n",
    "merged_data['fraud_percentage'] = (merged_data['fraud_count'] / merged_data['transaction_count']) * 100\n",
    "\n",
    "# Handling missing fraud counts: Replace NaN with 0 (if an account has no fraud)\n",
    "merged_data['fraud_percentage'] = merged_data['fraud_percentage'].fillna(0)\n",
    "\n",
    "# Print the percentage of fraudulent transactions for the top 10 accounts, along with accountNumber\n",
    "print(\"Top 10 Accounts with highest fraud percentage and their fraud percentage\")\n",
    "print(merged_data[['accountNumber', 'fraud_percentage']].sort_values(by='fraud_percentage', ascending=False).head(10).reset_index(drop=True))\n",
    "\n",
    "# ✅ Total number of transactions in the entire dataset\n",
    "total_transactions = total_transactions_frequency['transaction_count'].sum()\n",
    "\n",
    "# ✅ Total number of fraudulent transactions\n",
    "fraud_transactions_frequency['fraud_count'] = fraud_transactions_frequency['fraud_count'].fillna(0)\n",
    "total_fraud_transactions = fraud_transactions_frequency['fraud_count'].sum()\n",
    "print(f\"🚨 Total number of fraudulent transactions across all accounts: {int(total_fraud_transactions)}\")\n",
    "\n",
    "overall_fraud_rate = (total_fraud_transactions / total_transactions) * 100\n",
    "print(f\"⚠️ Overall fraud rate in the dataset: {overall_fraud_rate:.2f}%\")\n",
    "\n",
    "print(merged_data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fd41c",
   "metadata": {},
   "source": [
    "19. Is there a difference in spending behavior between fraudulent and non-fraudulent transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bea6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = sorted_df.groupby('isFraud')['transactionAmount'].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c630d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "sns.boxplot(data=sorted_df, x='isFraud', y='transactionAmount', hue='isFraud', palette={False: 'green', True: 'red'}, legend=False)\n",
    "plt.xlabel('Fraudulent Transaction?')\n",
    "plt.ylabel('Transaction Amount')\n",
    "plt.title('Comparison of Spending: Fraud vs Non-Fraud Transactions')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342283e1",
   "metadata": {},
   "source": [
    "Insights\n",
    "1. Highest number of transaction is 10,034 by account number 318001076.\n",
    "2. Highest number of fraudulent transaction is 302 by account number 311710839.\n",
    "3. Fraud_percentage is 100% for account 981286839 , and 50% for account 638423733.\n",
    "4. Total number of transactions acroll all accounts: 641914\n",
    "5. Total number of fraudulent transactions across all accounts: 11302\n",
    "6. Overall fraud rate is 1.76%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb44b2a",
   "metadata": {},
   "source": [
    "More on comparing fraudulent and non fraudulent transactions\n",
    "1. Fraudulent transactions are, on average, higher in value. (Based on mean)\n",
    "2. Fraudulent transactions also have greater variability - not only are they larger on average, but also more unpredictable. (Based on SD)\n",
    "3. Median for frauds is more than double that of non-frauds. Median is more resistant to outliers, so this confirms fraud transactions are genuinely higher, not just due to a few big outliers.\n",
    "4. 75% of non-fraud transactions are under 186.44 but 75% of frauds go up to 324.82.\n",
    "5. The maximum transaction values are comparable - large outliers happend in both categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1237542f",
   "metadata": {},
   "source": [
    "How many transaction are done by the accountNumber 981286839 and other top accounts with highest fraud percentage in the year 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()\n",
    "\n",
    "merged_data.sort_values(by='fraud_percentage',ascending=False).head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40493508",
   "metadata": {},
   "source": [
    "20. What is the highest transaction amount?\n",
    "What is the distribution of transactionAmount? Are there any outliers?\n",
    "What is the overall transaction amount and top accounts by that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Highest transaction amount is :\")\n",
    "print(sorted_df['transactionAmount'].max())\n",
    "print(\"Lowest transaction amount is: \")\n",
    "print(sorted_df['transactionAmount'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(data=sorted_df, x='transactionAmount', bins=40, kde=True, color='skyblue')\n",
    "\n",
    "# Format x-axis with commas\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "# Set x-axis limits and tick intervals\n",
    "plt.xlim(0, 2500)\n",
    "plt.xticks(range(0, 2501, 300))  # Set ticks every 100 units\n",
    "\n",
    "plt.xlabel('Transaction Amount')\n",
    "plt.ylabel('Frequency of that Transaction amount')\n",
    "plt.title('Distribution of Transaction Amounts (Focused Range)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data.drop(columns='transaction_amount_overall', inplace=True)\n",
    "\n",
    "# merged_data.info()\n",
    "\n",
    "# Remove old column first if it exists\n",
    "if 'transaction_amount_overall' in merged_data.columns:\n",
    "    merged_data.drop(columns='transaction_amount_overall', inplace=True)\n",
    "\n",
    "# Calculate transaction amount per account\n",
    "transaction_amount_overall = sorted_df.groupby('accountNumber')['transactionAmount'].sum().reset_index()\n",
    "\n",
    "# Rename before merging to avoid conflict\n",
    "transaction_amount_overall.rename(columns={'transactionAmount': 'transaction_amount_overall'}, inplace=True)\n",
    "\n",
    "# Merge cleanly\n",
    "merged_data = pd.merge(merged_data, transaction_amount_overall, on='accountNumber', how='left')\n",
    "\n",
    "top_accounts = merged_data.sort_values(by='transaction_amount_overall', ascending=False).head(10).reset_index(drop=True)\n",
    "print(top_accounts[['accountNumber', 'transaction_amount_overall']])\n",
    "\n",
    "\n",
    "min_accounts = merged_data.sort_values(by='transaction_amount_overall', ascending=True).head(10).reset_index(drop=True)\n",
    "print(min_accounts[[\"accountNumber\", \"transaction_amount_overall\"]])\n",
    "\n",
    "merged_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b827349",
   "metadata": {},
   "source": [
    "The highest transaction amount in one go is 1825.25 rupees.\n",
    "\n",
    "Account with overall highest transaction about over the year is AccountNumber 318001076 with amount 14,57,470.51.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filter for realistic range (e.g., 0 to 15,000)\n",
    "sns.histplot(data=merged_data, x='transaction_amount_overall', bins=30, kde=True, color='skyblue')\n",
    "\n",
    "# Format x-axis with commas\n",
    "plt.gca().xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "\n",
    "# Set x-axis limits based on your actual data range\n",
    "plt.xlim(0, 1500000)  # You can adjust the upper limit if needed\n",
    "\n",
    "plt.xlabel('Total Transaction Amount per Account')\n",
    "plt.ylabel('Number of Accounts')\n",
    "plt.title('Distribution of Transaction Amounts (Focused Range)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "sorted_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e259b4e3",
   "metadata": {},
   "source": [
    "21. availableMoney vs isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342eb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sorted_df['availableMoney'].max())\n",
    "\n",
    "print(sorted_df['availableMoney'].min())\n",
    "\n",
    "\n",
    "# Define balance bins\n",
    "bins = [-1500, 0, 5000, 10000, 15000, 20000, 30000, 40000, 50000]\n",
    "\n",
    "labels = [f'{bins[i]}–{bins[i+1]}' for i in range(len(bins)-1)]\n",
    "\n",
    "# Group data without creating a new column\n",
    "binned = pd.cut(sorted_df['availableMoney'], bins=bins, labels=labels, include_lowest=True)\n",
    "grouped = sorted_df.groupby(binned, observed=True)['isFraud'].agg(total='count', fraud='sum')\n",
    "grouped['fraud_rate'] = (grouped['fraud'] / grouped['total']) * 100\n",
    "\n",
    "print(grouped)\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "grouped['total'].plot(kind='bar', color='lightblue', ax=ax1)\n",
    "ax1.set_ylabel('Transaction Count', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_xlabel('Available Money Range')\n",
    "ax1.set_title('Fraud Rate and Transaction Volume by Available Money')\n",
    "ax1.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# Add fraud rate as line\n",
    "ax2 = ax1.twinx()\n",
    "grouped['fraud_rate'].plot(kind='line', color='red', marker='o', ax=ax2)\n",
    "ax2.set_ylabel('Fraud Rate (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc37430",
   "metadata": {},
   "source": [
    "22. currentBalance vs isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84480c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sorted_df['currentBalance'].max())\n",
    "\n",
    "print(sorted_df['currentBalance'].min())\n",
    "\n",
    "\n",
    "# Define balance bins\n",
    "bins = range(0, 50000, 5000)\n",
    "labels = [f'{bins[i]}–{bins[i+1]}' for i in range(len(bins)-1)]\n",
    "\n",
    "# Group data without creating a new column\n",
    "binned = pd.cut(sorted_df['currentBalance'], bins=bins, labels=labels, include_lowest=True)\n",
    "grouped = sorted_df.groupby(binned, observed=True)['isFraud'].agg(total='count', fraud='sum')\n",
    "grouped['fraud_rate'] = (grouped['fraud'] / grouped['total']) * 100\n",
    "\n",
    "print(grouped)\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "grouped['total'].plot(kind='bar', color='lightblue', ax=ax1)\n",
    "ax1.set_ylabel('Transaction Count', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_xlabel('Current Balance Range')\n",
    "ax1.set_title('Fraud Rate and Transaction Volume by Current Balance')\n",
    "ax1.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# Add fraud rate as line\n",
    "ax2 = ax1.twinx()\n",
    "grouped['fraud_rate'].plot(kind='line', color='red', marker='o', ax=ax2)\n",
    "ax2.set_ylabel('Fraud Rate (%)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8bc37",
   "metadata": {},
   "source": [
    "## Customer, CVV, expirationDate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9038ca",
   "metadata": {},
   "source": [
    "23. Normally after how long time of opening account the address is changed?\n",
    "24. From today's date it we see which are the oldest and newest accounts\n",
    "25. In which day maximum accounts are opened?\n",
    "26. Check enteredCVV and cardCVV mismatches, and calculate percentage of mismatch\n",
    "27. cardPresent = False vs Fraud\n",
    "28. cardPresent = True case vs Fraud\n",
    "29. Are card-present vs card-absent entry modes associated with different transaction amounts?\n",
    "30. CVV mismtach and isFraud comparison using cross tab\n",
    "31. expirationDateKeyInMatch and isFraud comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727254ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns related to customer information\n",
    "customer_columns = [\n",
    "    'accountNumber',\n",
    "    'customerId',\n",
    "    'creditLimit',\n",
    "    'availableMoney',\n",
    "    'cardCVV',\n",
    "    'enteredCVV',\n",
    "    'cardLast4Digits',\n",
    "    'currentExpDate',\n",
    "    'accountOpenDate',\n",
    "    'dateOfLastAddressChange',\n",
    "    'currentBalance',\n",
    "    'expirationDateKeyInMatch',\n",
    "    'cardPresent'\n",
    "]\n",
    "\n",
    "# # # Create the customer DataFrame\n",
    "# customer_df = df1[customer_columns].drop_duplicates(subset='accountNumber').reset_index(drop=True)\n",
    "\n",
    "customer_df = df1.sort_values(by='transactionDateTime', ascending=False) \\\n",
    "                 .drop_duplicates(subset='accountNumber') \\\n",
    "                 .reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(customer_df[['availableMoney', 'creditLimit', 'currentBalance']].describe())\n",
    "\n",
    "# # Preview the DataFrame\n",
    "# print(\"Customer DataFrame:\")\n",
    "# print(customer_df.head())\n",
    "\n",
    "# print(\n",
    "#     customer_df[['accountNumber', 'currentBalance']]       # Select only these two columns\n",
    "#     .sort_values(by='currentBalance', ascending=False)     # Sort by currentBalance (highest first)\n",
    "#     .reset_index(drop=True)                                # Reset index after sorting (drop old index)\n",
    "#     .head()                                                # Show top 5 rows\n",
    "# )\n",
    "\n",
    "# # print(df1.info())\n",
    "\n",
    "print(df1[['availableMoney', 'creditLimit', 'currentBalance', 'transactionAmount']].describe())\n",
    "print(customer_df[['accountNumber','currentBalance']].sort_values(by='currentBalance',ascending=False).head().reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b26f3a",
   "metadata": {},
   "source": [
    "23. Normally after how long time of opening account the address is changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df['add_change_gap'] = (customer_df['dateOfLastAddressChange']- customer_df['accountOpenDate']).dt.days\n",
    "print(customer_df[['accountNumber','add_change_gap']].sort_values(by='add_change_gap', ascending=False).reset_index(drop=True).head(10))\n",
    "\n",
    "average_gap = customer_df['add_change_gap'].mean()\n",
    "print(f\"\\nOverall average address change gap (in days): {average_gap: .2f}\")\n",
    "\n",
    "print(\"After opening account how many customer have changed the address\")\n",
    "changed_after_opening = customer_df[customer_df['add_change_gap']>0]\n",
    "\n",
    "print(f\"\\nNumber of customers who changed the address after opening account: {changed_after_opening.shape[0]} \")\n",
    "print(changed_after_opening[['accountNumber','add_change_gap']].sort_values(by='add_change_gap',ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f116d8",
   "metadata": {},
   "source": [
    "24. From today's date it we see which are the oldest and newest accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#customer_df = customer_df.drop(columns=['accountAge'])\n",
    "today = pd.Timestamp.today()\n",
    "customer_df['accountAge'] = (today - customer_df['accountOpenDate']).dt.days\n",
    "\n",
    "print(\"\\nTop 5 oldest accounts:\")\n",
    "print(customer_df[['accountNumber','accountOpenDate','accountAge']]\n",
    "      .sort_values(by='accountAge', ascending=False)\n",
    "      .reset_index(drop=True)\n",
    "      .head())\n",
    "\n",
    "print(\"\\nTop 5 new accounts\")\n",
    "print(customer_df[['accountNumber','accountOpenDate','accountAge']]\n",
    "      .sort_values(by='accountAge',ascending=True)\n",
    "      .reset_index(drop=True)\n",
    "      .head())\n",
    "\n",
    "#Oldest account\n",
    "oldest_account = customer_df.loc[customer_df['accountAge'].idxmax()]\n",
    "print(f\"\\n The oldest account is:\\nAccount Number: {oldest_account['accountNumber']},\"\n",
    "      f\"Opened on: {oldest_account['accountOpenDate'].date()} ,\"\n",
    "      f\" Age: {oldest_account['accountAge']} days \")\n",
    "\n",
    "#finding the newest account\n",
    "\n",
    "newest_account = customer_df.loc[customer_df['accountAge'].idxmin()]\n",
    "\n",
    "print(f\"\\n The newest account is:\\nAccount Number: {newest_account['accountNumber']},\"\n",
    "      f\"Opened on: {newest_account['accountOpenDate'].date()} ,\"\n",
    "      f\" Age: {newest_account['accountAge']} days \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152f953d",
   "metadata": {},
   "source": [
    "25. In which day maximum accounts are opened?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f737dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_open_day_counts = customer_df.groupby('accountOpenDate').size()\n",
    "\n",
    "max_open_day = account_open_day_counts.idxmax()\n",
    "max_open_count = account_open_day_counts.max()\n",
    "\n",
    "print(\"\\n Top 5 days with most account openings:\")\n",
    "print(account_open_day_counts.sort_values(ascending=False).head())\n",
    "\n",
    "print(f\"The maximum number of accounts were opened on {max_open_day.date()},with {max_open_count} accounts.\")\n",
    "\n",
    "print(\"Average count of accounts opened in a day:\", account_open_day_counts.mean())\n",
    "print(\"Minimum count of acounts opened in a day:\", account_open_day_counts.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ec58f",
   "metadata": {},
   "source": [
    "26. Check mismatches between entered CVV and actual CVV and calculate mismatch_percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ade8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new column to mark mismatches between entered and actual CVV\n",
    "sorted_df['cvv_mismatch'] = sorted_df['enteredCVV'] != sorted_df['cardCVV']\n",
    "\n",
    "print(\"Account Number and corresponding: cvv_mismatch counts\")\n",
    "print(sorted_df.groupby('accountNumber')['cvv_mismatch'].sum().sort_values(ascending=False))\n",
    "\n",
    "# Step 2: Group by account and calculate total transactions and mismatches\n",
    "fraudulent_df = sorted_df.groupby('accountNumber').agg(\n",
    "    total_transactions=('cvv_mismatch', 'count'),\n",
    "    mismatch_count=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Calculate percentage of mismatches\n",
    "fraudulent_df['mismatch_percentage'] = (fraudulent_df['mismatch_count'] / fraudulent_df['total_transactions']) * 100\n",
    "\n",
    "\n",
    "\n",
    "#fradulent_df only contains those accounts whose cvv mismatch_percentage is greater than 0\n",
    "\n",
    "fraudulent_df = fraudulent_df[fraudulent_df['mismatch_percentage']>0]\n",
    "\n",
    "print(fraudulent_df.sort_values(by='mismatch_percentage',ascending=False).head(10).reset_index(drop=True))\n",
    "\n",
    "# Filter accounts with more than 10% mismatch, then sort by mismatch percentage\n",
    "print(fraudulent_df[fraudulent_df['mismatch_percentage'] > 10].sort_values(by='mismatch_percentage', ascending=False).head(40).reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896384cc",
   "metadata": {},
   "source": [
    "We checked for enteredCVV and  cardCVV mismatch, first we counted the total transactions number and then mismatch count for each account number and then grouped those accounts whose mismatch_percentage is greater than 0 in a dataframe fradulent_df.\n",
    "\n",
    "In fradulent_df one account with 95.65% mismatch rate, similary 39 accounts with mismatch rate above 10%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44dc831",
   "metadata": {},
   "source": [
    "27. Now check cardpresent = False case vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628489d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check distinct values in 'cardPresent' column\n",
    "print(sorted_df['cardPresent'].unique())\n",
    "print(sorted_df['cardPresent'].value_counts(dropna=False))\n",
    "\n",
    "# Step 2: Filter data for card-absent transactions\n",
    "card_absent_df = sorted_df[sorted_df['cardPresent'] == False]\n",
    "\n",
    "# Step 3: Group and compute mismatch stats for card-absent transactions\n",
    "fraudulent_card_absent_df = card_absent_df.groupby('accountNumber').agg(\n",
    "    total_transactions_card_absent=('cvv_mismatch', 'count'),\n",
    "    cvv_mismatch_count_card_absent=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 4: Calculate mismatch percentage\n",
    "fraudulent_card_absent_df['cvv_mismatch_percentage_card_absent'] = (\n",
    "    fraudulent_card_absent_df['cvv_mismatch_count_card_absent'] / fraudulent_card_absent_df['total_transactions_card_absent']\n",
    ") * 100\n",
    "\n",
    "\n",
    "total_mismatches_while_card_absent = card_absent_df['cvv_mismatch'].sum()\n",
    "print(\"Total CVV mismatches (card absent):\", total_mismatches_while_card_absent)\n",
    "\n",
    "# Step 6: Calculate totals\n",
    "total_transactions = fraudulent_card_absent_df['total_transactions_card_absent'].sum()\n",
    "total_mismatches = fraudulent_card_absent_df['cvv_mismatch_count_card_absent'].sum()\n",
    "\n",
    "# Step 7: Calculate overall percentage\n",
    "overall_mismatch_percentage = (total_mismatches / total_transactions) * 100\n",
    "\n",
    "# Step 8: Create a summary row as a DataFrame\n",
    "summary_row = pd.DataFrame({\n",
    "    'accountNumber': ['TOTAL'],\n",
    "    'total_transactions_card_absent': [total_transactions],\n",
    "    'cvv_mismatch_count_card_absent': [total_mismatches],\n",
    "    'cvv_mismatch_percentage_card_absent': [overall_mismatch_percentage]\n",
    "})\n",
    "\n",
    "# Step 9: Append the summary row to the original DataFrame\n",
    "fraudulent_card_absent_df = pd.concat([fraudulent_card_absent_df, summary_row], ignore_index=True)\n",
    "\n",
    "# # Step 10: Print the final DataFrame\n",
    "# print(fraudulent_df1)\n",
    "\n",
    "# print(\"Top 20 accounts with card absent and high cvv mismatch rate\")\n",
    "# print(fraudulent_df1.sort_values(by='cvv_mismatch_percentage_card_absent', ascending=False).head(20).reset_index(drop=True))\n",
    "\n",
    "print(\"Creating fraudulent_df2 to store data for cvv_mismatch_percentage_card_absent greater than 10%\")\n",
    "\n",
    "fraudulent_card_absent_df1 = fraudulent_card_absent_df[fraudulent_card_absent_df['cvv_mismatch_percentage_card_absent']>10]\n",
    "print(fraudulent_card_absent_df1.sort_values(by='cvv_mismatch_percentage_card_absent',ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab73f3e",
   "metadata": {},
   "source": [
    "1. Total transaction with card not present( card absent) are: 340453\n",
    "2. Total trasnaction with card absent and cvvMismatch are: 3120\n",
    "3. For this case cvv_mismatch_percentage_card_present > 10 are kept in dataframe: fraudulent_card_absent_df1\n",
    "4. There are accounts with 100% mismatch percentage (238223440 - 9/9), (443926651 - 1/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba97ce",
   "metadata": {},
   "source": [
    "28. cardPresent = True case vs Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5498bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter data for card-present transactions\n",
    "card_present_df = sorted_df[sorted_df['cardPresent'] == True]\n",
    "\n",
    "# Step 2: Group and compute CVV mismatch stats for card-present transactions\n",
    "fraudulent_card_present_df = card_present_df.groupby('accountNumber').agg(\n",
    "    total_transactions_card_present=('cvv_mismatch', 'count'),\n",
    "    cvv_mismatch_count_card_present=('cvv_mismatch', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Step 3: Calculate mismatch percentage\n",
    "fraudulent_card_present_df['cvv_mismatch_percentage_card_present'] = (\n",
    "    fraudulent_card_present_df['cvv_mismatch_count_card_present'] / fraudulent_card_present_df['total_transactions_card_present']\n",
    ") * 100\n",
    "\n",
    "# Step 4: Add summary row (totals)\n",
    "summary_row_present = pd.DataFrame({\n",
    "    'accountNumber': ['TOTAL'],\n",
    "    'total_transactions_card_present': [fraudulent_card_present_df['total_transactions_card_present'].sum()],\n",
    "    'cvv_mismatch_count_card_present': [fraudulent_card_present_df['cvv_mismatch_count_card_present'].sum()],\n",
    "    'cvv_mismatch_percentage_card_present': [\n",
    "        (fraudulent_card_present_df['cvv_mismatch_count_card_present'].sum() / \n",
    "         fraudulent_card_present_df['total_transactions_card_present'].sum()) * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "fraudulent_card_present_df = pd.concat([fraudulent_card_present_df, summary_row_present], ignore_index=True)\n",
    "print(fraudulent_card_present_df)\n",
    "\n",
    "# Step 5: Filter accounts with >10% mismatch\n",
    "fraudulent_card_present_df1 = fraudulent_card_present_df[\n",
    "    fraudulent_card_present_df['cvv_mismatch_percentage_card_present'] > 10\n",
    "]\n",
    "\n",
    "# Display results\n",
    "print(fraudulent_card_present_df1.sort_values(by='cvv_mismatch_percentage_card_present', ascending=False).reset_index(drop=True).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd5379",
   "metadata": {},
   "source": [
    "1. Total transaction with card present are: 301461\n",
    "2. Total trasnaction with card present and cvvMismatch are: 2817\n",
    "3. For this case cvv_mismatch_percentage_card_present > 10 are kept in dataframe: fraudulent_card_present_df1\n",
    "4. There are accounts with 100% mismatch percentage (140105230 - 11/11), (380948187 - 1/1), (386190390 - 1/1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b709e3",
   "metadata": {},
   "source": [
    "29. Are card-present vs card-absent entry modes associated with different transaction amounts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ef336",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_mode_stats = sorted_df.groupby('cardPresent')['transactionAmount'].describe()\n",
    "entry_mode_stats.rename(index={True: 'Card Present', False: 'Card Absent'}, inplace=True)\n",
    "print(entry_mode_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01fee5",
   "metadata": {},
   "source": [
    "Insights:\n",
    "1. Card-Present transactions tend to have a slightly higher average ( 141.93 vs 129.17) and median amount. This may reflect more in-store purchases.\n",
    "2. CV = SD/mean * 100 , A CV of 0 indicates no variability, all data points are identitcal. ( 0 -10 : Low variability, data points are tightly clustered around mean, 10-30 : Moderate variability, 30 -100 : high variability, >100: very high variability). Here both SDs are similar, both are of high variabililty slightly card absent is more.\n",
    "3. Card absent is more frequent entry mode ( 340k). Could indicate increasing reliance on e-commerce or card-not-present purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.crosstab(sorted_df['cardPresent'], sorted_df['isFraud'], margins=True, margins_name= \"Total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c663a",
   "metadata": {},
   "source": [
    "cardPresent = False i.e card Absent cases have 6624 fraud\n",
    "cardPresent = True i.e. card present cases have 4678 fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for fraud vs card-present\n",
    "fraud_pivot = sorted_df.pivot_table(index='cardPresent', columns='isFraud', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Plot a stacked bar chart\n",
    "fraud_pivot.plot(kind='bar', stacked=True, figsize=(8,6), color=['green', 'red'])\n",
    "plt.title('Fraud vs Card Present/Absent Transactions')\n",
    "plt.xlabel('Card Present (True = Yes, False = No)')\n",
    "plt.ylabel('Count of Transactions')\n",
    "plt.xticks([0, 1], ['Card Present', 'Card Absent'], rotation=0)\n",
    "plt.legend(title='Fraud', labels=['Non-Fraud', 'Fraud'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc0816a",
   "metadata": {},
   "source": [
    "30. CVV Mismatch and isFraud Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1582a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.shape\n",
    "sorted_df.columns\n",
    "fraud_crosstab = pd.crosstab(\n",
    "    sorted_df['cvv_mismatch'],\n",
    "    sorted_df['isFraud'],\n",
    "    rownames=['CVV Mismatch'],\n",
    "    colnames=['Is Fraud'],\n",
    "    margins=True  # adds totals for rows and columns\n",
    ")\n",
    "\n",
    "print(fraud_crosstab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396175b8",
   "metadata": {},
   "source": [
    "Most transactions (635,977 out of 641,914) did not have a CVV mismatch.\n",
    "\n",
    "CVV mismatch occurred in only ~0.92% of transactions (5937 / 641914).\n",
    "\n",
    "Fraud rate when CVV matched:\n",
    "\n",
    "11,107 / 635,977 ≈ 1.75%\n",
    "\n",
    "Fraud rate when CVV mismatched:\n",
    "\n",
    "195 / 5,937 ≈ 3.28%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd393285",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvv_mismatch_pivot = sorted_df.pivot_table(index='cvv_mismatch', columns='isFraud', aggfunc='size', fill_value=0)\n",
    "\n",
    "#plot stacked bar chart\n",
    "cvv_mismatch_pivot.plot(kind='bar', stacked=True, figsize=(8,6), color = ['green','red'])\n",
    "plt.title('Fraud vs CVV Match/Mismatch transactions')\n",
    "plt.xlabel('CVV Mismatch (True = Yes, False = No)')\n",
    "plt.ylabel('Count of Transactions')\n",
    "plt.xticks([0,1],['CVV match', 'CVV_mismatch'], rotation=0)\n",
    "plt.legend(title='Fraud', labels =['Non Fraud', 'Fraud'])\n",
    "plt.show()\n",
    "\n",
    "# sorted_df.columns\n",
    "print(sorted_df['cvv_mismatch'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae18420",
   "metadata": {},
   "source": [
    "31. expirationDateKeyInMatch and isFraud comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b272b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sorted_df['expirationDateKeyInMatch'].unique())\n",
    "\n",
    "sorted_df[\"expirationDateKeyInMatch\"].value_counts()\n",
    "expiration_fraud_crosstab_percent = pd.crosstab(\n",
    "    sorted_df['expirationDateKeyInMatch'],\n",
    "    sorted_df['isFraud'],\n",
    "    rownames=['expiration_Mismtach'],\n",
    "    colnames=['Is Fraud'],\n",
    "    margins=True  # adds totals for rows and columns\n",
    ")\n",
    "\n",
    "print(expiration_fraud_crosstab_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafec763",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. Only 969 transactions had an expiration date mismatch — a very small fraction (~0.15%) of total transactions.\n",
    "2. Fraud rate when expiration matched: 11289/640945 =  approx. 1.76%\n",
    "3. Fraud rate when expiration mismatched: 13/969 = approx. 1.34%\n",
    "\n",
    "\n",
    "❗ Insight:\n",
    "Surprisingly, the fraud rate is slightly lower when expiration mismatches occur (1.34%) than when they match (1.76%).\n",
    "\n",
    "This suggests that expiration date mismatches are not a strong indicator of fraud in dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6962b2",
   "metadata": {},
   "source": [
    "## posEntryMode and posConditionCode Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ea282",
   "metadata": {},
   "source": [
    "32. What are the most frequent POS entry modes?\n",
    "33. Is fraud more common in any particular entry mode?\n",
    "34. What are the most common POS condition codes?\n",
    "35. How different condition codes relate to fraud?\n",
    "36. Are some condition codes tried to specific merchant categories or regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5669b",
   "metadata": {},
   "source": [
    "32. What are the most frequent POS entry modes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5600d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['posEntryMode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578d71f",
   "metadata": {},
   "source": [
    "Most frequent POS Entry Modes are 5 (chip read), 9(Manual entry), and 2 (Magnetic Strip swipe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543ee3d",
   "metadata": {},
   "source": [
    "33. Is fraud more common in any particular entry mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_entry = (sorted_df.groupby('posEntryMode')['isFraud'].mean()*100).sort_values(ascending = False)\n",
    "print(fraud_by_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed34db",
   "metadata": {},
   "source": [
    "Yes, Fraud rate is more common in Manual Entry(9) 2.7% and Advanced methods (QR, bluetooth , wallets ->90) 2.01 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca768f4",
   "metadata": {},
   "source": [
    "34. What are the most common POS condition codes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95d71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['posConditionCode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5867d",
   "metadata": {},
   "source": [
    "Customer present (Chip read or magnetic swipe can be used) is most common POS condition followed by Mail/Phone/Online Order (card-not-present).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bd5ea",
   "metadata": {},
   "source": [
    "35. How different condition codes relate to fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e6060",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_condition = (sorted_df.groupby('posConditionCode')['isFraud'].mean()*100).sort_values(ascending = False)\n",
    "print(fraud_by_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d49b7",
   "metadata": {},
   "source": [
    "99.0\tUnknown or other — This might be used when the system can’t determine the condition of the transaction. This could also represent some fraudulent or suspicious activity or any conditions that don’t fit into the usual categories.\n",
    "\n",
    "Approx 3.68 percentage of fraudulent in posConditionCode 99, followed by approx. 1.82 in posConditionCode 1 and at last for 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d866f",
   "metadata": {},
   "source": [
    "36. Are some condition codes tried to specific merchant categories or regions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ac9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sorted_df['posConditionCode'], sorted_df['merchantCategoryCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab96a1",
   "metadata": {},
   "source": [
    "This shows all transaction are happening mostly through posConditionCode 1 (customer present) in all merchant category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad4105",
   "metadata": {},
   "source": [
    "By Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96056bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(sorted_df['posConditionCode'], sorted_df['acqCountry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e79c8eb",
   "metadata": {},
   "source": [
    "## Date and time features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da82fee",
   "metadata": {},
   "source": [
    "37. Are there time periods with more fraud?\n",
    "38. Is fraud more common during weekends or weekday?\n",
    "99. What is the age of accounts? (opendate to first transaction date)/ (current date - open date)\n",
    "40. Do newer accounts have more fraud compared to older ones?\n",
    "41. When most trasnactions happen ? (Month, day, hour)\n",
    "42. txn_hour vs isFraud visual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3ceee",
   "metadata": {},
   "source": [
    "37. Are there time periods with more fraud?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e270399",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_hour = sorted_df.groupby('txn_hour')['isFraud'].mean()\n",
    "fraud_by_day = sorted_df.groupby('txn_day')['isFraud'].mean()\n",
    "fraud_by_month = sorted_df.groupby('txn_month')['isFraud'].mean()\n",
    "\n",
    "print((fraud_by_hour*100).sort_values(ascending=False).head(10))\n",
    "print((fraud_by_day*100).sort_values(ascending=False).head(10))\n",
    "print((fraud_by_month*100).sort_values(ascending=False).head(10))\n",
    "\n",
    "max_day = (fraud_by_day * 100).idxmax()\n",
    "max_value = (fraud_by_day * 100).max()\n",
    "print(f\"Max fraud happens on day: {max_day} with a fraud rate of {max_value:.2f}%\")\n",
    "\n",
    "\n",
    "max_month = (fraud_by_month * 100).idxmax()\n",
    "max_value = (fraud_by_month * 100).max()\n",
    "print(f\"Max fraud happens on month: {max_month} with a fraud rate of {max_value:.2f}%\")\n",
    "\n",
    "max_hour = (fraud_by_hour * 100).idxmax()\n",
    "max_value = (fraud_by_hour * 100).max()\n",
    "print(f\"Max fraud happens on hour: {max_hour} with a fraud rate of {max_value:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e618f68",
   "metadata": {},
   "source": [
    "38. Is fraud more common during weekends or weekday?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8330be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['weekday'] = sorted_df['transactionDateTime'].dt.weekday\n",
    "sorted_df['is_weekend'] = sorted_df['weekday'].isin([5, 6])\n",
    "\n",
    "sorted_df.groupby('is_weekend')['isFraud'].mean()\n",
    "\n",
    "sorted_df['weekday_name'] = sorted_df['transactionDateTime'].dt.day_name()\n",
    "\n",
    "# Count of all transactions by weekday\n",
    "total_txns = sorted_df['weekday_name'].value_counts().sort_index()\n",
    "\n",
    "# Count of fraudulent transactions by weekday\n",
    "fraud_txns = sorted_df[sorted_df['isFraud'] == True]['weekday_name'].value_counts().sort_index()\n",
    "\n",
    "# Combine into a summary table\n",
    "weekday_summary = pd.DataFrame({\n",
    "    'Total_Transactions': total_txns,\n",
    "    'Fraud_Transactions': fraud_txns\n",
    "}).fillna(0)\n",
    "\n",
    "# Add fraud rate\n",
    "weekday_summary['Fraud_Rate'] = (weekday_summary['Fraud_Transactions'] / weekday_summary['Total_Transactions'])*100\n",
    "weekday_summary = weekday_summary.sort_values('Fraud_Rate', ascending=False)\n",
    "weekday_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced3f18",
   "metadata": {},
   "source": [
    "High Fraud in weekends (1.79% is Sunday and 1.78% in Saturday)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f2be8",
   "metadata": {},
   "source": [
    "39. What is the age of accounts? (opendate to first transaction date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['account_age_days'] = (sorted_df['transactionDateTime'] - sorted_df['accountOpenDate']).dt.days\n",
    "\n",
    "# Sort by account age in descending order\n",
    "print(sorted_df[['accountNumber', 'account_age_days']].sort_values(by='account_age_days', ascending=False).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450009e",
   "metadata": {},
   "source": [
    "40. Do newer accounts have more fraud compared to older ones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df['age_bin'] = pd.cut(sorted_df['account_age_days'], bins=[0,30,90,180,365,10000])\n",
    "\n",
    "# Group by age bins and compute fraud rate\n",
    "fraud_rate_by_age = sorted_df.groupby('age_bin', observed=True)['isFraud'].mean()*100\n",
    "\n",
    "print(fraud_rate_by_age)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab71194",
   "metadata": {},
   "source": [
    "41. When most trasnactions happen ? (Month, day, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df[['txn_hour', 'txn_month', 'txn_day']]\n",
    "\n",
    "# Count frequency of transactions\n",
    "hour_counts = sorted_df['txn_hour'].value_counts().sort_index()\n",
    "day_counts = sorted_df['txn_day'].value_counts().sort_index()\n",
    "month_counts = sorted_df['txn_month'].value_counts().sort_index()\n",
    "\n",
    "# Peak values\n",
    "peak_hour = hour_counts.idxmax()\n",
    "peak_day = day_counts.idxmax()\n",
    "peak_month = month_counts.idxmax()\n",
    "\n",
    "# Least values\n",
    "least_hour = hour_counts.idxmin()\n",
    "least_day = day_counts.idxmin()\n",
    "least_month = month_counts.idxmin()\n",
    "\n",
    "# Print with transaction counts\n",
    "print(f\"Most transactions occurred at hour: {peak_hour} ({hour_counts[peak_hour]} transactions)\")\n",
    "print(f\"Most transactions occurred on day: {peak_day} ({day_counts[peak_day]} transactions)\")\n",
    "print(f\"Most transactions occurred in month: {peak_month} ({month_counts[peak_month]} transactions)\")\n",
    "\n",
    "print(f\"Least transactions occurred at hour: {least_hour} ({hour_counts[least_hour]} transactions)\")\n",
    "print(f\"Least transactions occurred on day: {least_day} ({day_counts[least_day]} transactions)\")\n",
    "print(f\"Least transactions occurred in month: {least_month} ({month_counts[least_month]} transactions)\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot Hours\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(hour_counts.index, hour_counts.values, color='skyblue')\n",
    "plt.title('Transactions by Hour')\n",
    "plt.xlabel('Hour (0-23)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "# Plot Days\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(day_counts.index, day_counts.values, color='salmon')\n",
    "plt.title('Transactions by Day')\n",
    "plt.xlabel('Day (1-30)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "# Plot Months\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(month_counts.index, month_counts.values, color='lightgreen')\n",
    "plt.title('Transactions by Month')\n",
    "plt.xlabel('Month (1-12)')\n",
    "plt.ylabel('Number of Transactions')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329434bb",
   "metadata": {},
   "source": [
    "42. txn_hour vs isFraud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
